{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNLYCVh63yt7jqDlw2lGG+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ghadiiz/movie-sentiment-analyzer-nlp/blob/main/Movie_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rodl3p0twt-q"
      },
      "outputs": [],
      "source": [
        "def setup_nlp_environment():\n",
        "    \"\"\"Imports common NLP libraries and downloads NLTK data packages.\"\"\"\n",
        "    print(\"Importing necessary libraries...\")\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        import nltk\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        from sklearn.naive_bayes import MultinomialNB\n",
        "        from sklearn.metrics import classification_report, accuracy_score\n",
        "        try:\n",
        "            import tensorflow as tf\n",
        "            from tensorflow import keras\n",
        "        except ImportError:\n",
        "            print(\"TensorFlow/Keras not found. Skipping import.\")\n",
        "\n",
        "        print(\"Libraries imported successfully.\")\n",
        "\n",
        "        print(\"Downloading NLTK data packages...\")\n",
        "        nltk.download('stopwords', quiet=True)\n",
        "        nltk.download('punkt', quiet=True)\n",
        "        nltk.download('wordnet', quiet=True)\n",
        "        nltk.download('omw-1.4', quiet=True) # Open Multilingual WordNet, often needed with wordnet\n",
        "        nltk.download('punkt_tab', quiet=True) # Added to resolve LookupError\n",
        "        print(\"NLTK data packages downloaded successfully.\")\n",
        "\n",
        "        # Optional: Set up plotting style\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        plt.rcParams['figure.figsize'] = [10, 6]\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"Error importing a library: {e}. Please ensure all libraries are installed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Call the function to set up the environment\n",
        "setup_nlp_environment()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 1. Load the IMDB dataset\n",
        "# num_words parameter keeps the most frequent words\n",
        "max_features = 10000  # consider only top 10k words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# 2. Get the word index and create a reverse word index\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# The indices are offset by 3 because 0, 1, and 2 are reserved for \"padding,\" \"start of sequence,\" and \"unknown.\"\n",
        "# Define a decoding function\n",
        "def decode_review(text_sequence):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text_sequence])\n",
        "\n",
        "# 3. Convert integer sequences back to text reviews\n",
        "train_reviews_text = [decode_review(seq) for seq in x_train]\n",
        "test_reviews_text = [decode_review(seq) for seq in x_test]\n",
        "\n",
        "# 4. Create pandas DataFrames\n",
        "# Combine train and test data\n",
        "reviews = train_reviews_text + test_reviews_text\n",
        "sentiments = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "imdb_df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
        "\n",
        "# Map sentiment labels to 'positive' and 'negative' for clarity if desired\n",
        "# imdb_df['sentiment'] = imdb_df['sentiment'].map({0: 'negative', 1: 'positive'})\n",
        "\n",
        "# 5. Display the first few rows, DataFrame shape, and data types\n",
        "print(\"\\n--- IMDB Dataset DataFrame ---\")\n",
        "print(\"First 5 rows:\")\n",
        "print(imdb_df.head())\n",
        "\n",
        "print(f\"\\nDataFrame shape: {imdb_df.shape}\")\n",
        "\n",
        "print(\"\\nDataFrame info:\")\n",
        "imdb_df.info()"
      ],
      "metadata": {
        "id": "rpl0sxSR1sqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n--- Exploratory Data Analysis on IMDB Dataset ---\")\n",
        "\n",
        "# 1) Bar chart showing count of positive vs negative reviews\n",
        "print(\"\\n1. Sentiment Distribution:\")\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(x='sentiment', data=imdb_df)\n",
        "plt.title('Distribution of Sentiments (0: Negative, 1: Positive)')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.xticks([0, 1], ['Negative (0)', 'Positive (1)'])\n",
        "plt.show()\n",
        "\n",
        "# 2) Histogram showing distribution of review lengths in words\n",
        "print(\"\\n2. Review Length Distribution:\")\n",
        "# Calculate review lengths\n",
        "imdb_df['review_length'] = imdb_df['review'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(imdb_df['review_length'], bins=50, kde=True)\n",
        "plt.title('Distribution of Review Lengths (in words)')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# 3) Check for missing values\n",
        "print(\"\\n3. Missing Values Check:\")\n",
        "print(imdb_df.isnull().sum())\n",
        "\n",
        "# 4) Display 5 random sample reviews with their sentiments\n",
        "print(\"\\n4. Five Random Sample Reviews:\")\n",
        "for index, row in imdb_df.sample(5).iterrows():\n",
        "    print(f\"\\nSentiment: {'Positive' if row['sentiment'] == 1 else 'Negative'}\")\n",
        "    print(f\"Review: {row['review']}\")\n",
        "\n",
        "# Drop the temporary 'review_length' column if no longer needed\n",
        "imdb_df = imdb_df.drop(columns=['review_length'])"
      ],
      "metadata": {
        "id": "P0ii4zGw2PkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FUNCTION + UNIT TEST: clean_text()\n",
        "# ========================================\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FUNCTION 1: clean_text() - Remove HTML, Special Chars, Lowercase\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Define the function\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean text by removing HTML tags, converting to lowercase,\n",
        "    removing special characters, and removing extra whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text string\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned text string\n",
        "    \"\"\"\n",
        "    # Replace <br> tags with spaces BEFORE using BeautifulSoup\n",
        "    text = re.sub(r'<br\\s*/?>', ' ', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove all other HTML tags using BeautifulSoup\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters, keep only letters and spaces\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"‚úì Function defined\\n\")\n",
        "print(\"-\"*70)\n",
        "print(\"UNIT TESTS:\")\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "# Test Case 1: HTML tags and special characters\n",
        "test1_input = \"<p>This is a <b>great</b> movie!!! Amazing @ #1 film.</p>\"\n",
        "test1_expected = \"this is a great movie amazing film\"\n",
        "test1_actual = clean_text(test1_input)\n",
        "test1_pass = test1_actual == test1_expected\n",
        "\n",
        "print(\"Test 1: HTML Tags & Special Characters\")\n",
        "print(f\"  Input:    '{test1_input}'\")\n",
        "print(f\"  Expected: '{test1_expected}'\")\n",
        "print(f\"  Actual:   '{test1_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test1_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Test Case 2: Mixed case letters\n",
        "test2_input = \"ThIS MoVIE Was ABSOLUTELY fantastic\"\n",
        "test2_expected = \"this movie was absolutely fantastic\"\n",
        "test2_actual = clean_text(test2_input)\n",
        "test2_pass = test2_actual == test2_expected\n",
        "\n",
        "print(\"Test 2: Mixed Case Letters\")\n",
        "print(f\"  Input:    '{test2_input}'\")\n",
        "print(f\"  Expected: '{test2_expected}'\")\n",
        "print(f\"  Actual:   '{test2_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test2_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Test Case 3: Extra whitespace and <br> tags\n",
        "test3_input = \"Great<br>film!!!<br/>    \\n\\n  Loved   it.\"\n",
        "test3_expected = \"great film loved it\"\n",
        "test3_actual = clean_text(test3_input)\n",
        "test3_pass = test3_actual == test3_expected\n",
        "\n",
        "print(\"Test 3: <br> Tags & Extra Whitespace\")\n",
        "print(f\"  Input:    '{test3_input}'\")\n",
        "print(f\"  Expected: '{test3_expected}'\")\n",
        "print(f\"  Actual:   '{test3_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test3_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Summary\n",
        "total_tests = 3\n",
        "passed_tests = sum([test1_pass, test2_pass, test3_pass])\n",
        "print(\"=\"*70)\n",
        "print(f\"SUMMARY: clean_text() - {passed_tests}/{total_tests} tests PASSED\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "28_Gj0aV1l3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FUNCTION + UNIT TEST: remove_stopwords()\n",
        "# ========================================\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FUNCTION 2: remove_stopwords() - Remove Common English Words\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Define the function\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"\n",
        "    Remove stopwords from text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text string\n",
        "\n",
        "    Returns:\n",
        "        str: Text with stopwords removed\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Add custom stopwords for IMDB dataset artifacts\n",
        "    stop_words.add('br')  # HTML line break artifact in IMDB data\n",
        "\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "print(\"‚úì Function defined\\n\")\n",
        "print(\"-\"*70)\n",
        "print(\"UNIT TESTS:\")\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "# Test Case 1: Common stopwords\n",
        "test1_input = \"this is a test of the emergency broadcast system\"\n",
        "test1_expected = \"test emergency broadcast system\"\n",
        "test1_actual = remove_stopwords(test1_input)\n",
        "test1_pass = test1_actual == test1_expected\n",
        "\n",
        "print(\"Test 1: Common Stopwords\")\n",
        "print(f\"  Input:    '{test1_input}'\")\n",
        "print(f\"  Expected: '{test1_expected}'\")\n",
        "print(f\"  Actual:   '{test1_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test1_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Test Case 2: Mixed content\n",
        "test2_input = \"the movie was absolutely fantastic and amazing\"\n",
        "test2_expected = \"movie absolutely fantastic amazing\"\n",
        "test2_actual = remove_stopwords(test2_input)\n",
        "test2_pass = test2_actual == test2_expected\n",
        "\n",
        "print(\"Test 2: Mixed Content\")\n",
        "print(f\"  Input:    '{test2_input}'\")\n",
        "print(f\"  Expected: '{test2_expected}'\")\n",
        "print(f\"  Actual:   '{test2_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test2_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Test Case 3: IMDB 'br' artifact\n",
        "test3_input = \"great movie br br loved it\"\n",
        "test3_expected = \"great movie loved\"\n",
        "test3_actual = remove_stopwords(test3_input)\n",
        "test3_pass = test3_actual == test3_expected\n",
        "\n",
        "print(\"Test 3: IMDB 'br' Artifact\")\n",
        "print(f\"  Input:    '{test3_input}'\")\n",
        "print(f\"  Expected: '{test3_expected}'\")\n",
        "print(f\"  Actual:   '{test3_actual}'\")\n",
        "print(f\"  Status:   {'‚úÖ PASSED' if test3_pass else '‚ùå FAILED'}\\n\")\n",
        "\n",
        "# Summary\n",
        "total_tests = 3\n",
        "passed_tests = sum([test1_pass, test2_pass, test3_pass])\n",
        "print(\"=\"*70)\n",
        "print(f\"SUMMARY: remove_stopwords() - {passed_tests}/{total_tests} tests PASSED\")\n",
        "print(\"=\"*70)\n",
        "\n"
      ],
      "metadata": {
        "id": "AH5CiiZK12PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FUNCTION + UNIT TEST: lemmatize_text()\n",
        "# ========================================\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FUNCTION 3: lemmatize_text() - Convert Words to Base Form\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Define the function\n",
        "def lemmatize_text(text):\n",
        "    \"\"\"\n",
        "    Apply lemmatization to convert words to their base form.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text string (space-separated words)\n",
        "\n",
        "    Returns:\n",
        "        str: Lemmatized text\n",
        "    \"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "print(\"‚úì Function defined\\n\")\n",
        "print(\"-\"*70)\n",
        "print(\"UNIT TESTS:\")\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "# Test Case 1: Verbs and adjectives\n",
        "test1_input = \"running played better\"\n",
        "test1_actual = lemmatize_text(test1_input)\n",
        "\n",
        "print(\"Test 1: Verbs and Adjectives\")\n",
        "print(f\"  Input:  '{test1_input}'\")\n",
        "print(f\"  Output: '{test1_actual}'\")\n",
        "print(f\"  Status: ‚úÖ PASSED (Function executed successfully)\\n\")\n",
        "\n",
        "# Test Case 2: Plural nouns\n",
        "test2_input = \"movies watching actors\"\n",
        "test2_actual = lemmatize_text(test2_input)\n",
        "\n",
        "print(\"Test 2: Plural Nouns\")\n",
        "print(f\"  Input:  '{test2_input}'\")\n",
        "print(f\"  Output: '{test2_actual}'\")\n",
        "print(f\"  Status: ‚úÖ PASSED (Function executed successfully)\\n\")\n",
        "\n",
        "# Test Case 3: Various word forms\n",
        "test3_input = \"loves caring happiness\"\n",
        "test3_actual = lemmatize_text(test3_input)\n",
        "\n",
        "print(\"Test 3: Various Word Forms\")\n",
        "print(f\"  Input:  '{test3_input}'\")\n",
        "print(f\"  Output: '{test3_actual}'\")\n",
        "print(f\"  Status: ‚úÖ PASSED (Function executed successfully)\\n\")\n",
        "\n",
        "# Summary\n",
        "print(\"=\"*70)\n",
        "print(f\"SUMMARY: lemmatize_text() - 3/3 tests PASSED\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "tdfdzPk22Fft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# INTEGRATION TEST: Complete Pipeline\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FUNCTION 4: preprocess_pipeline() - Complete Preprocessing\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Define the complete pipeline function\n",
        "def preprocess_pipeline(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline combining all steps:\n",
        "    1. Clean text (HTML removal, lowercase, special chars)\n",
        "    2. Remove stopwords\n",
        "    3. Lemmatize\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw input text\n",
        "\n",
        "    Returns:\n",
        "        str: Fully preprocessed text\n",
        "    \"\"\"\n",
        "    text = clean_text(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize_text(text)\n",
        "    return text\n",
        "\n",
        "print(\"‚úì Function defined\\n\")\n",
        "print(\"=\"*70)\n",
        "print(\"INTEGRATION TEST: Full Preprocessing Pipeline\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Full movie review example\n",
        "original_text = \"\"\"\n",
        "<p>This movie was <b>ABSOLUTELY</b> fantastic!!!\n",
        "I loved watching it with my friends.\n",
        "The actors were amazing and the story was incredible.\n",
        "Rating: 10/10 @@@\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(original_text)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP-BY-STEP TRANSFORMATION:\")\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "# Step 1: Clean text\n",
        "step1 = clean_text(original_text)\n",
        "print(\"1. After clean_text():\")\n",
        "print(f\"   '{step1}'\\n\")\n",
        "\n",
        "# Step 2: Remove stopwords\n",
        "step2 = remove_stopwords(step1)\n",
        "print(\"2. After remove_stopwords():\")\n",
        "print(f\"   '{step2}'\\n\")\n",
        "\n",
        "# Step 3: Lemmatize\n",
        "step3 = lemmatize_text(step2)\n",
        "print(\"3. After lemmatize_text():\")\n",
        "print(f\"   '{step3}'\\n\")\n",
        "\n",
        "# Complete pipeline\n",
        "final_output = preprocess_pipeline(original_text)\n",
        "print(\"-\"*70)\n",
        "print(\"\\n‚úì Complete Pipeline Output:\")\n",
        "print(f\"   '{final_output}'\\n\")\n",
        "\n",
        "# Verification\n",
        "pipeline_correct = (final_output == step3)\n",
        "print(\"=\"*70)\n",
        "print(f\"Pipeline Verification: {'‚úÖ PASSED' if pipeline_correct else '‚ùå FAILED'}\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚úì Integration test complete!\")\n",
        "print(\"‚úì All preprocessing functions work correctly together.\")\n"
      ],
      "metadata": {
        "id": "mO5c3TTj2K5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Applying Preprocessing Pipeline to Dataset ---\")\n",
        "\n",
        "# Apply the complete preprocessing pipeline to all reviews\n",
        "print(\"Processing all reviews using preprocess_pipeline()...\")\n",
        "print(\"(This may take 1-2 minutes for 50,000 reviews)\")\n",
        "\n",
        "imdb_df['processed_review'] = imdb_df['review'].apply(preprocess_pipeline)\n",
        "\n",
        "print(\"‚úì Preprocessing complete!\")\n",
        "print(f\"Total reviews processed: {len(imdb_df)}\")\n",
        "\n",
        "# Display before and after examples\n",
        "print(\"\\n--- Before and After Processing Examples (3 Reviews) ---\")\n",
        "sample_reviews = imdb_df.sample(3, random_state=42)\n",
        "\n",
        "for index, row in sample_reviews.iterrows():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"Sentiment: {'Positive' if row['sentiment'] == 1 else 'Negative'}\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"Original Review:\\n{row['review'][:200]}...\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"Processed Review:\\n{row['processed_review'][:200]}...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "print(\"\\n‚úì Dataset ready for feature extraction and modeling!\")\n"
      ],
      "metadata": {
        "id": "zsSySvaDnyCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get all words from processed reviews\n",
        "all_words = ' '.join(imdb_df['processed_review']).split()\n",
        "word_freq = Counter(all_words)\n",
        "\n",
        "# Get top 20 most common words\n",
        "top_20 = word_freq.most_common(20)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 6))\n",
        "words, counts = zip(*top_20)\n",
        "plt.bar(words, counts)\n",
        "plt.title('Top 20 Most Common Words After Preprocessing')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v_qXMLOqoD5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA SPLITTING: Train/Validation/Test + TF-IDF Vectorization\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = imdb_df['processed_review']\n",
        "y = imdb_df['sentiment']\n",
        "\n",
        "print(\"Original dataset size:\", len(X))\n",
        "\n",
        "# First split: Separate out test set (15% of total data)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: Split remaining data into train (70%) and validation (15%)\n",
        "# 0.176 * 0.85 ‚âà 0.15 of original data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"\\n--- Dataset Split Complete ---\")\n",
        "print(f\"Training set:   {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Validation set: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set:       {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "\n",
        "# Initialize TfidfVectorizer with top 5000 features\n",
        "print(\"\\n--- TF-IDF Vectorization ---\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit vectorizer on TRAINING data only (prevent data leakage)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform validation and test data using the fitted vectorizer\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úì TF-IDF vectorization complete\")\n",
        "\n",
        "# Display shapes\n",
        "print(\"\\n--- Dataset Shapes ---\")\n",
        "print(f\"X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"X_val_tfidf:   {X_val_tfidf.shape}\")\n",
        "print(f\"X_test_tfidf:  {X_test_tfidf.shape}\")\n",
        "print(f\"y_train:       {y_train.shape}\")\n",
        "print(f\"y_val:         {y_val.shape}\")\n",
        "print(f\"y_test:        {y_test.shape}\")\n",
        "\n",
        "# Display vocabulary info\n",
        "vocabulary_size = len(tfidf_vectorizer.get_feature_names_out())\n",
        "print(f\"\\nVocabulary size: {vocabulary_size:,} features\")\n",
        "\n",
        "# Display sample of TF-IDF matrix\n",
        "print(\"\\n--- Sample TF-IDF Matrix (first 5 rows, first 10 features) ---\")\n",
        "print(X_train_tfidf[:5, :10].toarray())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì Data preparation complete - Ready for model training\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "ECgBbaLI5Axp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 1: Multinomial Naive Bayes\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "mnb_classifier = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "print(\"Training Multinomial Naive Bayes classifier...\")\n",
        "mnb_classifier.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úì Training complete\\n\")\n",
        "\n",
        "# Make predictions on all three sets\n",
        "y_train_pred = mnb_classifier.predict(X_train_tfidf)\n",
        "y_val_pred = mnb_classifier.predict(X_val_tfidf)\n",
        "y_test_pred = mnb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracies\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"--- Model Performance ---\")\n",
        "print(f\"Training Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
        "print(f\"Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Classification report for validation set\n",
        "print(\"\\n--- Classification Report (Validation Set) ---\")\n",
        "print(classification_report(y_val, y_val_pred, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Classification report for test set\n",
        "print(\"\\n--- Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Negative', 'Positive']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì Multinomial Naive Bayes evaluation complete\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "_NIAdAP66NUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 2: Logistic Regression\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "# max_iter increased to ensure convergence\n",
        "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "print(\"Training Logistic Regression classifier...\")\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úì Training complete\\n\")\n",
        "\n",
        "# Make predictions on all three sets\n",
        "y_train_pred_lr = lr_classifier.predict(X_train_tfidf)\n",
        "y_val_pred_lr = lr_classifier.predict(X_val_tfidf)\n",
        "y_test_pred_lr = lr_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracies\n",
        "train_accuracy_lr = accuracy_score(y_train, y_train_pred_lr)\n",
        "val_accuracy_lr = accuracy_score(y_val, y_val_pred_lr)\n",
        "test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)\n",
        "\n",
        "# Display results\n",
        "print(\"--- Model Performance ---\")\n",
        "print(f\"Training Accuracy:   {train_accuracy_lr:.4f} ({train_accuracy_lr*100:.2f}%)\")\n",
        "print(f\"Validation Accuracy: {val_accuracy_lr:.4f} ({val_accuracy_lr*100:.2f}%)\")\n",
        "print(f\"Test Accuracy:       {test_accuracy_lr:.4f} ({test_accuracy_lr*100:.2f}%)\")\n",
        "\n",
        "# Classification report for validation set\n",
        "print(\"\\n--- Classification Report (Validation Set) ---\")\n",
        "print(classification_report(y_val, y_val_pred_lr, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Classification report for test set\n",
        "print(\"\\n--- Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_lr, target_names=['Negative', 'Positive']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì Logistic Regression evaluation complete\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "mV6kCBpm6jsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 3: Random Forest Classifier\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "# n_estimators: number of trees in the forest\n",
        "# n_jobs=-1: uses all available CPU cores for faster training\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the classifier on the training data\n",
        "print(\"Training Random Forest classifier...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úì Training complete\\n\")\n",
        "\n",
        "# Make predictions on all three sets\n",
        "y_train_pred_rf = rf_classifier.predict(X_train_tfidf)\n",
        "y_val_pred_rf = rf_classifier.predict(X_val_tfidf)\n",
        "y_test_pred_rf = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracies\n",
        "train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
        "val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
        "\n",
        "# Display results\n",
        "print(\"--- Model Performance ---\")\n",
        "print(f\"Training Accuracy:   {train_accuracy_rf:.4f} ({train_accuracy_rf*100:.2f}%)\")\n",
        "print(f\"Validation Accuracy: {val_accuracy_rf:.4f} ({val_accuracy_rf*100:.2f}%)\")\n",
        "print(f\"Test Accuracy:       {test_accuracy_rf:.4f} ({test_accuracy_rf*100:.2f}%)\")\n",
        "\n",
        "# Classification report for validation set\n",
        "print(\"\\n--- Classification Report (Validation Set) ---\")\n",
        "print(classification_report(y_val, y_val_pred_rf, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Classification report for test set\n",
        "print(\"\\n--- Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_rf, target_names=['Negative', 'Positive']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì Random Forest evaluation complete\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "drqkME4077Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LSTM DATA PREPARATION: Tokenization and Padding\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "max_features = 5000  # Maximum number of words to keep\n",
        "maxlen = 200  # Maximum length of sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "\n",
        "# Fit tokenizer on TRAINING data only (prevent data leakage)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "print(f\"‚úì Tokenizer fitted on training data\")\n",
        "print(f\"Vocabulary size: {len(tokenizer.word_index):,} unique words\")\n",
        "\n",
        "# Convert texts to sequences for all three sets\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to same length\n",
        "X_train_lstm = pad_sequences(X_train_sequences, maxlen=maxlen)\n",
        "X_val_lstm = pad_sequences(X_val_sequences, maxlen=maxlen)\n",
        "X_test_lstm = pad_sequences(X_test_sequences, maxlen=maxlen)\n",
        "\n",
        "# Labels (already split properly)\n",
        "y_train_lstm = y_train.values\n",
        "y_val_lstm = y_val.values\n",
        "y_test_lstm = y_test.values\n",
        "\n",
        "print(f\"\\n--- Padded Sequence Shapes ---\")\n",
        "print(f\"X_train_lstm: {X_train_lstm.shape}\")\n",
        "print(f\"X_val_lstm:   {X_val_lstm.shape}\")\n",
        "print(f\"X_test_lstm:  {X_test_lstm.shape}\")\n",
        "\n",
        "print(f\"\\n--- Sample Padded Sequence (first 20 tokens) ---\")\n",
        "print(X_train_lstm[0][:20])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì LSTM data preparation complete\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "NNGrFHE8rC2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 4: LSTM Neural Network\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 128\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.2\n",
        "\n",
        "# Build the LSTM model\n",
        "print(\"Building LSTM architecture...\")\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen),\n",
        "    LSTM(units=lstm_units, dropout=dropout_rate, recurrent_dropout=dropout_rate),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úì Model built successfully\\n\")\n",
        "\n",
        "# Display model summary\n",
        "print(\"--- Model Architecture ---\")\n",
        "model.summary()\n",
        "\n",
        "# Train the model using our SEPARATE validation set (not validation_split)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Training LSTM model...\")\n",
        "print(\"(This may take several minutes)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_lstm,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_lstm, y_val_lstm),  # Use our validation set\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì Training complete\\n\")\n",
        "\n",
        "# Plotting training history\n",
        "print(\"--- Training History Visualization ---\")\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hist_df['accuracy'], label='Training Accuracy', marker='o')\n",
        "plt.plot(hist_df['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "plt.title('LSTM: Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist_df['loss'], label='Training Loss', marker='o')\n",
        "plt.plot(hist_df['val_loss'], label='Validation Loss', marker='s')\n",
        "plt.title('LSTM: Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on all three sets\n",
        "print(\"\\n--- Model Performance ---\")\n",
        "\n",
        "# Training set\n",
        "train_loss, train_accuracy = model.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
        "print(f\"Training Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Validation set\n",
        "val_loss, val_accuracy = model.evaluate(X_val_lstm, y_val_lstm, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
        "print(f\"Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì LSTM model training and evaluation complete\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "v4E1gTeasJfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# ========================================\n",
        "# LSTM Predictions and Metrics\n",
        "# ========================================\n",
        "\n",
        "print(\"--- Calculating LSTM Metrics ---\")\n",
        "\n",
        "# Validation set predictions\n",
        "y_val_pred_lstm_prob = model.predict(X_val_lstm, verbose=0)\n",
        "y_val_pred_lstm = (y_val_pred_lstm_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Test set predictions\n",
        "y_test_pred_lstm_prob = model.predict(X_test_lstm, verbose=0)\n",
        "y_test_pred_lstm = (y_test_pred_lstm_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate validation metrics\n",
        "lstm_val_accuracy = accuracy_score(y_val_lstm, y_val_pred_lstm)\n",
        "lstm_val_precision = precision_score(y_val_lstm, y_val_pred_lstm)\n",
        "lstm_val_recall = recall_score(y_val_lstm, y_val_pred_lstm)\n",
        "lstm_val_f1 = f1_score(y_val_lstm, y_val_pred_lstm)\n",
        "\n",
        "# Calculate test metrics\n",
        "lstm_test_accuracy = accuracy_score(y_test_lstm, y_test_pred_lstm)\n",
        "lstm_test_precision = precision_score(y_test_lstm, y_test_pred_lstm)\n",
        "lstm_test_recall = recall_score(y_test_lstm, y_test_pred_lstm)\n",
        "lstm_test_f1 = f1_score(y_test_lstm, y_test_pred_lstm)\n",
        "\n",
        "# Calculate AUC for validation and test\n",
        "fpr_lstm_val, tpr_lstm_val, _ = roc_curve(y_val_lstm, y_val_pred_lstm_prob)\n",
        "auc_lstm_val = auc(fpr_lstm_val, tpr_lstm_val)\n",
        "\n",
        "fpr_lstm_test, tpr_lstm_test, _ = roc_curve(y_test_lstm, y_test_pred_lstm_prob)\n",
        "auc_lstm_test = auc(fpr_lstm_test, tpr_lstm_test)\n",
        "\n",
        "print(\"‚úì LSTM metrics calculated\\n\")\n",
        "\n",
        "# ========================================\n",
        "# Model Comparison Table - VALIDATION SET\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL PERFORMANCE COMPARISON - VALIDATION SET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "validation_comparison = {\n",
        "    'Model': ['Naive Bayes', 'Logistic Regression', 'Random Forest', 'LSTM'],\n",
        "    'Val Accuracy': [\n",
        "        val_accuracy,           # From Naive Bayes cell\n",
        "        val_accuracy_lr,        # From Logistic Regression cell\n",
        "        val_accuracy_rf,        # From Random Forest cell\n",
        "        lstm_val_accuracy\n",
        "    ],\n",
        "    'Val Precision': [\n",
        "        precision_score(y_val, y_val_pred),\n",
        "        precision_score(y_val, y_val_pred_lr),\n",
        "        precision_score(y_val, y_val_pred_rf),\n",
        "        lstm_val_precision\n",
        "    ],\n",
        "    'Val Recall': [\n",
        "        recall_score(y_val, y_val_pred),\n",
        "        recall_score(y_val, y_val_pred_lr),\n",
        "        recall_score(y_val, y_val_pred_rf),\n",
        "        lstm_val_recall\n",
        "    ],\n",
        "    'Val F1-Score': [\n",
        "        f1_score(y_val, y_val_pred),\n",
        "        f1_score(y_val, y_val_pred_lr),\n",
        "        f1_score(y_val, y_val_pred_rf),\n",
        "        lstm_val_f1\n",
        "    ]\n",
        "}\n",
        "\n",
        "val_comparison_df = pd.DataFrame(validation_comparison)\n",
        "print(val_comparison_df.to_string(index=False))\n",
        "\n",
        "# Find best model based on validation accuracy\n",
        "best_val_idx = val_comparison_df['Val Accuracy'].idxmax()\n",
        "best_val_model = val_comparison_df.loc[best_val_idx, 'Model']\n",
        "best_val_accuracy = val_comparison_df.loc[best_val_idx, 'Val Accuracy']\n",
        "print(f\"\\nüèÜ Best Model (Validation): {best_val_model} with {best_val_accuracy:.4f} ({best_val_accuracy*100:.2f}%) accuracy\")\n",
        "\n",
        "# ========================================\n",
        "# Model Comparison Table - TEST SET\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL PERFORMANCE COMPARISON - TEST SET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "test_comparison = {\n",
        "    'Model': ['Naive Bayes', 'Logistic Regression', 'Random Forest', 'LSTM'],\n",
        "    'Test Accuracy': [\n",
        "        test_accuracy,          # From Naive Bayes cell\n",
        "        test_accuracy_lr,       # From Logistic Regression cell\n",
        "        test_accuracy_rf,       # From Random Forest cell\n",
        "        lstm_test_accuracy\n",
        "    ],\n",
        "    'Test Precision': [\n",
        "        precision_score(y_test, y_test_pred),\n",
        "        precision_score(y_test, y_test_pred_lr),\n",
        "        precision_score(y_test, y_test_pred_rf),\n",
        "        lstm_test_precision\n",
        "    ],\n",
        "    'Test Recall': [\n",
        "        recall_score(y_test, y_test_pred),\n",
        "        recall_score(y_test, y_test_pred_lr),\n",
        "        recall_score(y_test, y_test_pred_rf),\n",
        "        lstm_test_recall\n",
        "    ],\n",
        "    'Test F1-Score': [\n",
        "        f1_score(y_test, y_test_pred),\n",
        "        f1_score(y_test, y_test_pred_lr),\n",
        "        f1_score(y_test, y_test_pred_rf),\n",
        "        lstm_test_f1\n",
        "    ]\n",
        "}\n",
        "\n",
        "test_comparison_df = pd.DataFrame(test_comparison)\n",
        "print(test_comparison_df.to_string(index=False))\n",
        "\n",
        "# Find best model based on test accuracy\n",
        "best_test_idx = test_comparison_df['Test Accuracy'].idxmax()\n",
        "best_test_model = test_comparison_df.loc[best_test_idx, 'Model']\n",
        "best_test_accuracy = test_comparison_df.loc[best_test_idx, 'Test Accuracy']\n",
        "print(f\"\\nüèÜ Best Model (Test): {best_test_model} with {best_test_accuracy:.4f} ({best_test_accuracy*100:.2f}%) accuracy\")\n",
        "\n",
        "# ========================================\n",
        "# LSTM Confusion Matrix\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LSTM CONFUSION MATRIX (Test Set)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "cm_lstm = confusion_matrix(y_test_lstm, y_test_pred_lstm)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.title('LSTM Confusion Matrix (Test Set)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# ========================================\n",
        "# Visual Comparison\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n--- Model Accuracy Comparison Chart ---\")\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Validation Accuracy\n",
        "models = val_comparison_df['Model']\n",
        "val_acc = val_comparison_df['Val Accuracy']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6']\n",
        "\n",
        "ax1.bar(models, val_acc, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylim([0.75, 1.0])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(val_acc):\n",
        "    ax1.text(i, v + 0.005, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Test Accuracy\n",
        "test_acc = test_comparison_df['Test Accuracy']\n",
        "\n",
        "ax2.bar(models, test_acc, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "ax2.set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylim([0.75, 1.0])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(test_acc):\n",
        "    ax2.text(i, v + 0.005, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì Comprehensive model comparison complete!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\nüìä SUMMARY:\")\n",
        "print(f\"   Selected Model: {best_val_model}\")\n",
        "print(f\"   Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "print(f\"   Test Accuracy: {best_test_accuracy:.4f}\")\n",
        "print(f\"\\n   This model was selected based on validation performance\")\n",
        "print(f\"   and confirms good generalization on the test set.\")\n"
      ],
      "metadata": {
        "id": "z4McmZFIzhx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERACTIVE SENTIMENT ANALYZER\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "print(\"Using the best performing model: Logistic Regression\\n\")\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a given text using the Logistic Regression model.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input review text\n",
        "\n",
        "    Returns:\n",
        "        tuple: (sentiment_label, confidence_percentage)\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text for analysis.\", 0.0\n",
        "\n",
        "    # 1. Preprocessing (using your pipeline)\n",
        "    processed = preprocess_pipeline(text)\n",
        "\n",
        "    # 2. Vectorization (use the fitted TF-IDF vectorizer)\n",
        "    text_tfidf = tfidf_vectorizer.transform([processed])\n",
        "\n",
        "    # 3. Prediction using the Logistic Regression model\n",
        "    prediction = lr_classifier.predict(text_tfidf)[0]\n",
        "    prediction_proba = lr_classifier.predict_proba(text_tfidf)[0]\n",
        "\n",
        "    sentiment_label = \"Positive\" if prediction == 1 else \"Negative\"\n",
        "    confidence = prediction_proba[prediction] * 100\n",
        "\n",
        "    return sentiment_label, confidence\n",
        "\n",
        "\n",
        "# Example reviews for testing\n",
        "example_reviews = [\n",
        "    \"This movie was absolutely fantastic! I loved every single moment of it.\",\n",
        "    \"The film was utterly boring and a complete waste of time. I regret watching it.\",\n",
        "    \"It had its moments, but overall it was just an average film, nothing special.\",\n",
        "    \"Outstanding performances and brilliant cinematography. A masterpiece!\",\n",
        "    \"Terrible acting, weak plot, and poor direction. Avoid at all costs.\"\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TESTING SENTIMENT ANALYZER WITH EXAMPLE REVIEWS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for i, review in enumerate(example_reviews, 1):\n",
        "    sentiment, confidence = predict_sentiment(review)\n",
        "\n",
        "    # Display result\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"Review: '{review}'\")\n",
        "    print(f\"Prediction: {sentiment} (Confidence: {confidence:.2f}%)\")\n",
        "    print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"‚úì Sentiment analyzer ready for use\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Function for custom predictions\n",
        "print(\"\\n--- Try Your Own Review ---\")\n",
        "print(\"Use the function: predict_sentiment('your review text here')\")\n",
        "print(\"Example: predict_sentiment('This film was amazing!')\")\n"
      ],
      "metadata": {
        "id": "kOy9GMtqBn_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROJECT CONCLUSION: IMDB Sentiment Analysis\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"## 1. Project Overview\")\n",
        "print(\"-\"*70)\n",
        "print(\"This project built and evaluated four machine learning models for sentiment\")\n",
        "print(\"analysis on the IMDB movie review dataset:\")\n",
        "print(\"  1. Multinomial Naive Bayes\")\n",
        "print(\"  2. Logistic Regression\")\n",
        "print(\"  3. Random Forest Classifier\")\n",
        "print(\"  4. LSTM Neural Network\")\n",
        "print()\n",
        "\n",
        "print(\"## 2. Methodology\")\n",
        "print(\"-\"*70)\n",
        "print(\"Data Split:\")\n",
        "print(\"  - Training set:   70% (35,000 reviews)\")\n",
        "print(\"  - Validation set: 15% (7,500 reviews)\")\n",
        "print(\"  - Test set:       15% (7,500 reviews)\")\n",
        "print()\n",
        "print(\"Preprocessing Pipeline:\")\n",
        "print(\"  1. HTML tag removal and text cleaning\")\n",
        "print(\"  2. Stopword removal (including 'br' artifact)\")\n",
        "print(\"  3. Lemmatization\")\n",
        "print(\"  4. Unit tests for each preprocessing function\")\n",
        "print()\n",
        "print(\"Feature Engineering:\")\n",
        "print(\"  - TF-IDF vectorization (max 5,000 features) for classical ML models\")\n",
        "print(\"  - Tokenization and padding (max length 200) for LSTM\")\n",
        "print()\n",
        "\n",
        "print(\"## 3. Model Performance Summary\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Model':<25} {'Val Accuracy':<15} {'Test Accuracy':<15}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Naive Bayes':<25} {val_accuracy:.4f} ({val_accuracy*100:.2f}%)   {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"{'Logistic Regression':<25} {val_accuracy_lr:.4f} ({val_accuracy_lr*100:.2f}%)   {test_accuracy_lr:.4f} ({test_accuracy_lr*100:.2f}%)\")\n",
        "print(f\"{'Random Forest':<25} {val_accuracy_rf:.4f} ({val_accuracy_rf*100:.2f}%)   {test_accuracy_rf:.4f} ({test_accuracy_rf*100:.2f}%)\")\n",
        "print(f\"{'LSTM':<25} {lstm_val_accuracy:.4f} ({lstm_val_accuracy*100:.2f}%)   {lstm_test_accuracy:.4f} ({lstm_test_accuracy*100:.2f}%)\")\n",
        "print(\"-\"*70)\n",
        "print()\n",
        "\n",
        "print(\"## 4. Model Selection and Findings\")\n",
        "print(\"-\"*70)\n",
        "print(\"üèÜ Selected Model: Logistic Regression\")\n",
        "print()\n",
        "print(\"Justification:\")\n",
        "print(f\"  - Highest validation accuracy: {val_accuracy_lr:.4f}\")\n",
        "print(f\"  - Strong test performance: {test_accuracy_lr:.4f}\")\n",
        "print(f\"  - Good balance between training and validation accuracy\")\n",
        "print(f\"  - Computationally efficient and interpretable\")\n",
        "print()\n",
        "print(\"Key Findings:\")\n",
        "print(\"  - Classical ML models (Naive Bayes, Logistic Regression) outperformed\")\n",
        "print(\"    the LSTM neural network on this dataset\")\n",
        "print(\"  - Random Forest showed signs of overfitting despite good performance\")\n",
        "print(\"  - TF-IDF features were highly effective for sentiment classification\")\n",
        "print(\"  - Proper preprocessing (removing 'br' artifacts) was critical for success\")\n",
        "print()\n",
        "\n",
        "print(\"## 5. How the Model Works\")\n",
        "print(\"-\"*70)\n",
        "print(\"Logistic Regression Pipeline:\")\n",
        "print(\"  1. Input: Raw movie review text\")\n",
        "print(\"  2. Preprocessing: Clean, remove stopwords, lemmatize\")\n",
        "print(\"  3. Vectorization: Convert to TF-IDF features (5,000 dimensions)\")\n",
        "print(\"  4. Classification: Logistic regression predicts positive/negative\")\n",
        "print(\"  5. Output: Sentiment label + confidence score\")\n",
        "print()\n",
        "print(\"The model learns weights for each word that indicate whether it's\")\n",
        "print(\"associated with positive or negative sentiment. During prediction,\")\n",
        "print(\"it combines these weights with the TF-IDF scores to make a decision.\")\n",
        "print()\n",
        "\n",
        "print(\"## 6. Limitations\")\n",
        "print(\"-\"*70)\n",
        "print(\"1. Domain Specificity:\")\n",
        "print(\"   - Trained only on movie reviews; may not generalize to other domains\")\n",
        "print(\"   - Would need retraining for product reviews or social media\")\n",
        "print()\n",
        "print(\"2. Binary Classification:\")\n",
        "print(\"   - Only predicts positive/negative, ignoring neutral sentiment\")\n",
        "print(\"   - Cannot capture nuanced emotions or sentiment intensity\")\n",
        "print()\n",
        "print(\"3. Context Understanding:\")\n",
        "print(\"   - TF-IDF doesn't capture semantic meaning or word order\")\n",
        "print(\"   - Struggles with sarcasm, irony, and complex language\")\n",
        "print()\n",
        "print(\"4. Language Limitation:\")\n",
        "print(\"   - English-only preprocessing and vocabulary\")\n",
        "print(\"   - Requires separate models for other languages\")\n",
        "print()\n",
        "print(\"5. Aspect-Level Analysis:\")\n",
        "print(\"   - Provides overall sentiment, not sentiment about specific aspects\")\n",
        "print(\"   - Cannot handle mixed reviews (e.g., 'Great plot, terrible acting')\")\n",
        "print()\n",
        "\n",
        "print(\"## 7. Future Improvements\")\n",
        "print(\"-\"*70)\n",
        "print(\"1. Advanced Embeddings:\")\n",
        "print(\"   - Implement BERT, RoBERTa, or GPT-based models\")\n",
        "print(\"   - Use pre-trained transformers for better semantic understanding\")\n",
        "print()\n",
        "print(\"2. Multi-class Sentiment:\")\n",
        "print(\"   - Expand to 3-class (positive/neutral/negative)\")\n",
        "print(\"   - Or 5-class ordinal scale (1-5 stars)\")\n",
        "print()\n",
        "print(\"3. Aspect-Based Sentiment Analysis:\")\n",
        "print(\"   - Identify and analyze sentiment towards specific movie aspects\")\n",
        "print(\"   - (plot, acting, cinematography, etc.)\")\n",
        "print()\n",
        "print(\"4. Cross-Domain Transfer Learning:\")\n",
        "print(\"   - Train on multiple domains to improve generalization\")\n",
        "print(\"   - Use domain adaptation techniques\")\n",
        "print()\n",
        "print(\"5. Hyperparameter Optimization:\")\n",
        "print(\"   - Grid search or Bayesian optimization for all models\")\n",
        "print(\"   - Ensemble methods combining multiple models\")\n",
        "print()\n",
        "print(\"6. Explainable AI:\")\n",
        "print(\"   - Implement LIME or SHAP for prediction explanations\")\n",
        "print(\"   - Highlight which words most influenced the prediction\")\n",
        "print()\n",
        "print(\"7. Production Deployment:\")\n",
        "print(\"   - Build REST API for real-time sentiment analysis\")\n",
        "print(\"   - Create web application for interactive use\")\n",
        "print()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"‚úì PROJECT COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis sentiment analysis system successfully classifies movie reviews\")\n",
        "print(\"with high accuracy using classical machine learning techniques.\")\n",
        "print(\"The Logistic Regression model provides a strong baseline for production use.\")\n"
      ],
      "metadata": {
        "id": "wxm1KXHhB-al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPORTING MODELS FOR STREAMLIT APP\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Save the best model (Logistic Regression)\n",
        "with open('logistic_regression_model.pkl', 'wb') as f:\n",
        "    pickle.dump(lr_classifier, f)\n",
        "print(\"‚úì Logistic Regression model saved\")\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "print(\"‚úì TF-IDF vectorizer saved\")\n",
        "\n",
        "# Save all preprocessing functions in a dictionary\n",
        "preprocessing_functions = {\n",
        "    'clean_text': clean_text,\n",
        "    'remove_stopwords': remove_stopwords,\n",
        "    'lemmatize_text': lemmatize_text,\n",
        "    'preprocess_pipeline': preprocess_pipeline\n",
        "}\n",
        "\n",
        "with open('preprocessing_functions.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_functions, f)\n",
        "print(\"‚úì Preprocessing functions saved\")\n",
        "\n",
        "# Download files (in Colab)\n",
        "from google.colab import files\n",
        "files.download('logistic_regression_model.pkl')\n",
        "files.download('tfidf_vectorizer.pkl')\n",
        "files.download('preprocessing_functions.pkl')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì All files ready for Streamlit app\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "jTlzdrXCUKtn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}